\chapter{Evaluation}
\label{chapter:evaluation}

After laying down the theoretical analysis of the scan algorithms and providing
an efficient implementation it is time to verify whether the expectations hold
up in reality. This chapter does so with a focus on six basic questions.

\begin{enumerate}
  \item Can the early pruning in \bwv{} beat the performance of \simdscan{}
despite of branching overhead?
  \item How large is this branching overhead?
  \item Is the early pruning probability difference of \bwv{} and \bs{} visible in practice?
  \item What is the impact of predicate selectivity on early pruning?
  \item How much time does it take to bring data in the formats required by the scanning algorithms.
  \item Are there visible improvements due to the bandwidth reduction of block-wise scanning?
\end{enumerate}

\section{Benchmark Setup}

All benchmarks were performed on a dual-CPU Intel Xeon E5-2697 v3 machine. This
Haswell setup had 56 physical and logical cores but all benchmarks only measure
single-core performance. The CPU has a last-level cache size of 35 megabytes.
Memory was supplied by eight banks with eight gigabytes of DDR4 RAM each,
running at 1067\,MHz. On the software side Ubuntu 14.04 was used and GCC 4.8
compiled the benchmark code, except for \simdscan{} which was using a binary
compiled with ICC.

\section{Comparing \simdscan{} to \bwv{}}

The first and most important evaluation result will be a direct comparison
between \simdscan{} and \bwv{}. As seen in figure~\ref{fig:eval:bwvsimdb8}. In
this configuration early pruning was performed after reading 4 bits as
suggested in~\cite{BitWeaving}.

\begin{figure}[h]
\pgfplotsset{footnotesize,width=0.75*\textwidth,height=6cm,compat=1.8}
\begin{center}
\begin{tikzpicture} \begin{axis}[
    title=\simdscan{} vs. \bwv{},
    ylabel={Runtime (ns)},
    ymin=0,%ymax=24000,
    xlabel={Bit Width},
    xmin=1,xmax=32,
    mark size=1pt,
    scaled ticks=false,
    legend columns=-1,
    legend entries={\simdscan{}, \bwv{}},
    legend to name=leg:bwvsimdb8,
    grid
]
\addplot+[only marks] table[header=false,col sep=semicolon, x index=2, y index=6] {data/AVX2_range_noblock_b4.csv};
\addplot+[only marks] table[header=false,col sep=semicolon, x index=2, y index=6] {data/BWV_range_noblock_b4.csv};
\end{axis}
\end{tikzpicture}

\begin{tikzpicture} \begin{axis}[
    ylabel={Bytes Read from DRAM},
    ymin=0,%ymax=24000,
    xlabel={Bit Width},
    xmin=1,xmax=32,
    mark size=1pt,
    scaled ticks=false,
    grid
]
\addplot+[only marks] table[header=false,col sep=semicolon, x index=2, y index=8] {data/AVX2_range_noblock_b4.csv};
\addplot+[only marks] table[header=false,col sep=semicolon, x index=2, y index=8] {data/BWV_range_noblock_b4.csv};
\end{axis}
\end{tikzpicture}
\ref*{leg:bwvsimdb8}
\end{center}
\caption{Runtime of a range predicate with \simdscan{} and \bwv{}, sum of eight
runs over $2^{25}$ random integers. \bwv{} group size is four.}
\label{fig:eval:bwvsimdb8}
\end{figure}

As described earlier the benchmark was run with multiple selectivities, which
are represented as a stack of markers in this chart. Since selectivity has
virtually no impact on the runtime of \simdscan{} the variance between the
selectivities can be interpreted as an indicator for the noise level. The read
bandwidth used by \simdscan{} is approximately 11 gigabytes per second and
scales linearly over all bit widths with only a few exceptions. 11 gigabytes
per second matches the bandwidth available to a single core on the Haswell
processor used. This was verified with a separate benchmark only touching every
cache line once. Total bandwidth is significantly higher but can only made use
of by utilizing multiple cores. The graph itself can be analyzed as four
different parts.

\begin{itemize}
  \item Bit widths $0-8$: due to the large amount of last-level cache
  available not all of the memory is read from DRAM but was kept in the cache
  over multiple iterations. This skews the result, however there is virtually
  no difference in scan performance between \simdscan{} and \bwv{}. Early
  pruning can theoretically abort the scan after four or eight bits but the
  probability calculated in chapter~\ref{chapter:analysis} is very low so no
  effect is observed.
  \item Bit widths $8-12$: as calculated earlier and visible in the memory
  graph early pruning is still not effective here. The overhead of the additional
  branch is slowing down \bwv{} in comparison to \simdscan{} which does not have
  any branching in its scan loop. \simdscan{} is the better scan algorithm for
  these common bit widths.
  \item Bit widths $12-20$: Early pruning starts to become more effective and
  less memory is loaded from DRAM. The early pruning overhead is clearly
  visible and yields a slower runtime than \simdscan{} so its still preferable
  over \bwv{}.
  \item Bit width $20-32$: Early pruning is very effective and beats the
  runtime of \simdscan{} with a growing margin. The performance curve is
  entirely flat and will stay the same if the bit width is extended any further.
  \bwv{} is the preferable algorithm for this kind of scan.
\end{itemize}

All in all this benchmark shows that \bwv{} can beat \simdscan{}, but it is not
always a clear win. It provides no advantage over \simdscan{} at low bit widths
and is slower at medium bit widths. Only at relatively large bit widths early
pruning can make up its own overhead and provide an advantage that grows larger
as the bit width gets larger. This contradicts the observations of the
\bwv{} paper~\cite{BitWeaving} where \bwv{} is significantly faster than all
other methods. It is very likely that a faulty implementation of \simdscan{} was
used for those benchmarks as it is very competitive.

\section{Reducing the early pruning overhead}

As seen in the last graphs there is a significant overhead in the area around
16 bits when comparing \bwv{} with \simdscan{}. This overhead comes from the
additional branching that has to be performed at every early pruning step. To
reduce the amount of branching one possible tweak is to reduce the number of
bits that are processed without early pruning. This diminishes the
effectiveness of early pruning though. For the benchmark in
figure~\ref{fig:eval:bwvsimdbgroups} early pruning was performed after every 4,
8 or 16 bits processed. The selectivity for this benchmark was fixed at $50\,\%$.

\begin{figure}[h]
\pgfplotsset{footnotesize,width=0.75*\textwidth,height=6cm,compat=1.8}
\begin{center}
\begin{tikzpicture} \begin{axis}[
    title=\simdscan{} vs. \bwv{},
    ylabel={Runtime (ns)},
    ymin=0,%ymax=24000,
    xlabel={Bit Width},
    xmin=1,xmax=32,
    mark size=1pt,
    scaled ticks=false,
    legend columns=-1,
    legend entries={\simdscan{}, \bwv{} B=4, \bwv{} B=8, \bwv{} B=16,},
    legend to name=leg:bwvsimdbgroups,
    grid
]
\addplot+[only marks] table[header=false,col sep=semicolon, x index=2, y index=6, each nth point=32, filter discard warning=false, unbounded coords=discard, skip rows between index={0}{2}] {data/AVX2_range_noblock_b4.csv};
\addplot+[only marks] table[header=false,col sep=semicolon, x index=2, y index=6, each nth point=32, filter discard warning=false, unbounded coords=discard, skip rows between index={0}{2}] {data/BWV_range_noblock_b4.csv};
\addplot+[only marks] table[header=false,col sep=semicolon, x index=2, y index=6, each nth point=32, filter discard warning=false, unbounded coords=discard, skip rows between index={0}{2}] {data/BWV_range_noblock_b8.csv};
\addplot+[only marks] table[header=false,col sep=semicolon, x index=2, y index=6, each nth point=32, filter discard warning=false, unbounded coords=discard, skip rows between index={0}{2}] {data/BWV_range_noblock_b16.csv};
\end{axis}
\end{tikzpicture}

\begin{tikzpicture} \begin{axis}[
    ylabel={Bytes Read from DRAM},
    ymin=0,%ymax=24000,
    xlabel={Bit Width},
    xmin=1,xmax=32,
    mark size=1pt,
    scaled ticks=false,
    grid
]
\addplot+[only marks] table[header=false,col sep=semicolon, x index=2, y index=8, each nth point=32, filter discard warning=false, unbounded coords=discard, skip rows between index={0}{2}] {data/AVX2_range_noblock_b4.csv};
\addplot+[only marks] table[header=false,col sep=semicolon, x index=2, y index=8, each nth point=32, filter discard warning=false, unbounded coords=discard, skip rows between index={0}{2}] {data/BWV_range_noblock_b4.csv};
\addplot+[only marks] table[header=false,col sep=semicolon, x index=2, y index=8, each nth point=32, filter discard warning=false, unbounded coords=discard, skip rows between index={0}{2}] {data/BWV_range_noblock_b8.csv};
\addplot+[only marks] table[header=false,col sep=semicolon, x index=2, y index=8, each nth point=32, filter discard warning=false, unbounded coords=discard, skip rows between index={0}{2}] {data/BWV_range_noblock_b16.csv};
\end{axis}
\end{tikzpicture}
\ref*{leg:bwvsimdbgroups}
\end{center}
\caption{Runtime of a range predicate with \simdscan{} and \bwv{}, sum of eight
runs over $2^{25}$ random integers. Varying group sizes.}
\label{fig:eval:bwvsimdbgroups}
\end{figure}

As expected smaller group sizes work better with regard to the number of bytes
read from DRAM as early pruning is a lot more effective. The impact on
performance is very small though, the expected improvement due to fewer
mispredicted branches is not visible. Nullifying the overhead does not seem
possible.

As the difference is very small a block size of eight was chosen for the
following experiments, as it compares better to \bs{} which has an intrinsic
group size of eight due to processing values at the byte level.

\section{Comparing \bwv{} to \bs{}}

\section{Comparing predicates and selectivity}

So far only a range predicate was tested. For random data in a uniform
distribution this has the very nice property of hitting the worst case very
rarely. As a reminder, for the used predicate of the form $x\le y < z$ the worst
case is triggered when $y$ is either equal to $x$ or $z$. So for the next
benchmark this worst case will be investigated. For reasons of simplicity an
equality predicate was used, but the observation also applies to any inequality
or range predicate. Only 8, 16, 24 and 32 bits are evaluated because others are
not directly supported by \bs{}. The results in runtime and DRAM reads are
plotted in figure~\ref{fig:eval:equalbig}.

\begin{figure}[h]
\pgfplotsset{footnotesize,width=4cm,height=6cm,compat=1.8}
\begin{center}
\begin{tikzpicture} \begin{axis}[
    ylabel={Runtime (ns)},
    ymin=0,ymax=100000000,
    xlabel={Bit Width},
    xtick={8,16,24,32},
    mark size=1pt,
    scaled ticks=false,
    legend columns=-1,
    %legend entries={\simdscan{}, \bwv{}, \bs{}},
    legend to name=leg:equalbig,
    grid
]
\addplot+[only marks] table[header=false,col sep=semicolon, x index=2, y index=6] {data/AVX2_equalbig.csv};
\addlegendentry{\simdscan{}}
% Horrible hack to populate the legend.
\addplot+[color=red] coordinates {(8,-100)};
\addlegendentry{\bwv{}}
\addplot+[color=olive] coordinates {(8,-100)};
\addlegendentry{\bs{}}
\end{axis}
\end{tikzpicture}
\begin{tikzpicture} \begin{axis}[
    ymin=0,ymax=100000000,
    yticklabels={,,},
    xlabel={Bit Width},
    xtick={8,16,24,32},
    mark size=1pt,
    scaled ticks=false,
    grid
]
\addplot+[color=red,only marks] table[header=false,col sep=semicolon, x index=2, y index=6] {data/BWV_equalbig.csv};
\end{axis}
\end{tikzpicture}
\begin{tikzpicture} \begin{axis}[
    ymin=0,ymax=100000000,
    yticklabels={,,},
    xlabel={Bit Width},
    xtick={8,16,24,32},
    mark size=1pt,
    scaled ticks=false,
    grid
]
\addplot+[color=olive,only marks] table[header=false,col sep=semicolon, x index=2, y index=6] {data/BS_equalbig.csv};
\end{axis}
\end{tikzpicture}

\begin{tikzpicture} \begin{axis}[
    ylabel={Bytes Read from DRAM},
    ymin=0,ymax=1200000000,
    xlabel={Bit Width},
    xtick={8,16,24,32},
    mark size=1pt,
    scaled ticks=false,
    grid
]
\addplot+[only marks] table[header=false,col sep=semicolon, x index=2, y index=8] {data/AVX2_equalbig.csv};
\end{axis}
\end{tikzpicture}
\begin{tikzpicture} \begin{axis}[
    ymin=0,ymax=1200000000,
    yticklabels={,,},
    xlabel={Bit Width},
    xtick={8,16,24,32},
    mark size=1pt,
    scaled ticks=false,
    grid
]
\addplot+[color=red,only marks] table[header=false,col sep=semicolon, x index=2, y index=8] {data/BWV_equalbig.csv};
\end{axis}
\end{tikzpicture}
\begin{tikzpicture} \begin{axis}[
    ymin=0,ymax=1200000000,
    yticklabels={,,},
    xlabel={Bit Width},
    xtick={8,16,24,32},
    mark size=1pt,
    scaled ticks=false,
    grid
]
\addplot+[color=olive,only marks] table[header=false,col sep=semicolon, x index=2, y index=8] {data/BS_equalbig.csv};
\end{axis}
\end{tikzpicture}

\ref*{leg:equalbig}
\end{center}
\caption{Runtime of an equality predicate with \simdscan{}, \bwv{} and \bs{},
sum of eight runs over $2^{25}$ random integers. 32 different selectivities
between $100\,\%$ and $0\,\%$.}
\label{fig:eval:equalbig}
\end{figure}

\begin{itemize}
  \item \simdscan{} is the base line. \bwv{} and \bs{} read at most as much data
    as \simdscan{}. The performance represents the maximum amount of data one
    CPU core can process at the given time, so any other algorithm can not be
    faster unless it reads less data.
  \item When the same amount of data is read the performance of \bwv{} tends to
    be almost identical to \simdscan{}. On the one hand this equality predicate
    does very little arithmetic work compared the range predicate shown earlier
    on the other hand early pruning does not work well so the early exit branch
    can be easily predicted by the hardware.
  \item Early pruning is more effective for \bs{} than for \bwv{} but
    performance tends to be slightly worse. The implementation of \bs{} is not
    entirely memory bound like \simdscan{} and \bwv{} are.
\end{itemize}

One important fact that is not represented in this graph is that for \bwv{} and
\bs{} about half of the points are in the topmost position. This is shown in
detail in figure~\ref{fig:eval:equalbigselectivity} which shows the results
against the selectivity on a logarithmic scale. The results are only shown for a
bit width of 32 as this shows early pruning in action for both \bwv{} and \bs{}.

\begin{figure}[h]
\pgfplotsset{footnotesize,width=0.75*\textwidth,height=6cm,compat=1.8}
\pgfplotsset{select coords between index/.style 2 args={
    x filter/.code={
        \ifnum\coordindex<#1\def\pgfmathresult{}\fi
        \ifnum\coordindex>#2\def\pgfmathresult{}\fi
    }
}}
\begin{center}

\begin{tikzpicture} \begin{semilogxaxis}[
    ylabel={Runtime (ns)},
    ymin=0,ymax=100000000,
    xlabel={Selectivity},
    mark size=1pt,
    scaled ticks=false,
    legend columns=-1,
    legend entries={\simdscan{}, \bwv{}, \bs{}},
    legend to name=leg:equalbigselectivity,
    grid
]
\addplot+ [select coords between index={0}{32}] table[header=false,col sep=semicolon, x index=5, y index=6,filter discard warning=false] {data/AVX2_equalbig.csv};
\addplot+ [select coords between index={0}{32}] table[header=false,col sep=semicolon, x index=5, y index=6,filter discard warning=false] {data/BWV_equalbig.csv};
\addplot+ [select coords between index={0}{32}] table[header=false,col sep=semicolon, x index=5, y index=6,filter discard warning=false] {data/BS_equalbig.csv};
\end{semilogxaxis}
\end{tikzpicture}

\begin{tikzpicture} \begin{semilogxaxis}[
    ylabel={Bytes Read from DRAM},
    ymin=0,ymax=1200000000,
    xlabel={Selectivity},
    mark size=1pt,
    scaled ticks=false,
    grid
]
\addplot+ [select coords between index={0}{32}] table[header=false,col sep=semicolon, x index=5, y index=8,filter discard warning=false] {data/AVX2_equalbig.csv};
\addplot+ [select coords between index={0}{32}] table[header=false,col sep=semicolon, x index=5, y index=8,filter discard warning=false] {data/BWV_equalbig.csv};
\addplot+ [select coords between index={0}{32}] table[header=false,col sep=semicolon, x index=5, y index=8,filter discard warning=false] {data/BS_equalbig.csv};
\end{semilogxaxis}
\end{tikzpicture}

\ref*{leg:equalbigselectivity}
\end{center}
\caption{Different selectivities for \simdscan{}, \bwv{} and \bs{} for code
width 32.}
\label{fig:eval:equalbigselectivity}
\end{figure}

The graph clearly shows the early pruning patterns calculated in
chapter~\ref{chapter:analysis}. The bit width of 32 bits is also rather large so
early pruning can work decently here and the branch overhead does not penalize
\bwv{} in comparison to \simdscan{}. For \bs{} the situation looks a bit
different though as there are obvious deficiencies in performance here. It is
unclear why there is a performance advantage over \bwv{} and \simdscan{} for
very high selectivities.

\section{Packing and Unpacking}

Packing the data into the representation required by the scan algorithm and
unpacking them for consumption are two operations that are often overlooked when
measuring scan performance. While packing performance is usually done once for a
column which is scanned many times, unpacking is necessary to materialize the
results. This can be circumvented by keeping the data available in multiple
formats, one optimized for scanning and another optimized for unpacking, but
this obviously requires twice the amount of memory.
Figure~\ref{fig:eval:packunpack} shows packing of 32 bit values into the scan
representation of various sizes and the reverse, unpacking the scan
representation back into 32 bit values. For \simdscan{} at bit width 32 both
operations are equivalent to \texttt{memcpy}, performing a verbatim copy and not
modifying the data at all.

\begin{figure}[h]
\pgfplotsset{footnotesize,width=0.75*\textwidth,height=6cm,compat=1.8}
\begin{center}
\begin{tikzpicture} \begin{axis}[
    title={Packing},
    ylabel={Runtime (ns)},
    ymin=0,%ymax=24000,
    xlabel={Bit Width},
    xmin=1,xmax=32,
    mark size=1pt,
    scaled ticks=false,
    legend columns=-1,
    legend entries={\simdscan{}, \bwv{}, \bs{}},
    legend to name=leg:packunpack,
    grid
]
\addplot+[only marks] table[header=false,col sep=semicolon, x index=2, y index=6] {data/AVX2_pack.csv};
\addplot+[only marks] table[header=false,col sep=semicolon, x index=2, y index=6] {data/BWV_pack.csv};
\addplot+[only marks] table[header=false,col sep=semicolon, x index=2, y index=6] {data/BS_pack.csv};
\end{axis}
\end{tikzpicture}

\begin{tikzpicture} \begin{axis}[
    title={Unpacking},
    ylabel={Runtime (ns)},
    ymin=0,%ymax=24000,
    xlabel={Bit Width},
    xmin=1,xmax=32,
    mark size=1pt,
    scaled ticks=false,
    grid
]
\addplot+[only marks] table[header=false,col sep=semicolon, x index=2, y index=6] {data/AVX2_unpack.csv};
\addplot+[only marks] table[header=false,col sep=semicolon, x index=2, y index=6] {data/BWV_unpack.csv};
\addplot+[only marks] table[header=false,col sep=semicolon, x index=2, y index=6] {data/BS_unpack.csv};
\end{axis}
\end{tikzpicture}
\ref*{leg:packunpack}
\end{center}
\caption{Packing 32 bit values into \simdscan{}, \bwv{} and \bs{}
representations and the reverse. 256 values were transformed at a time.}
\label{fig:eval:packunpack}
\end{figure}

The most obvious issue is that \bwv{} is orders of magnitudes slower than the
other two representations. This is due to the amount of arithmetic needed to
extract and insert individual bits while manipulating fully bytes or more can be
done much more efficiently with shifts and vector shuffles. It should also be
noted that packing is more expensive than unpacking in this scenario.

For \simdscan{} and \bs{} runtime is extremely close to the speed of memory as
seen in the 32 bit case of packing. The difference in performance between the
two is mostly due to the \bs{} packing algorithm making use of SIMD while the
others were implemented using scalar 32 or 64 bit integers. There is still more
potential for optimization here.

In conclusion it is certainly feasible to use the in-memory representation of
\simdscan{} or \bs{} as the storage format for both scanning and extraction of
values, unpacking from \bwv{} is prohibitively expensive so its usage is
restricted to being an index.
